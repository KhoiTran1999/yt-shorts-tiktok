import scrapetube
import requests
import re
import json
import time
from database import add_video_to_db, add_channel_to_db

# === 1. HÃ€M Cá»¨U VIá»†N (Gá»ŒI OEMBED) ===
def fetch_video_info_fallback(video_id):
    """
    Khi scrapetube khÃ´ng tráº£ vá» title, dÃ¹ng hÃ m nÃ y Ä‘á»ƒ há»i trá»±c tiáº¿p YouTube.
    API: oEmbed (CÃ´ng khai, khÃ´ng cáº§n key, ráº¥t nhanh)
    """
    try:
        # URL chuáº©n Ä‘á»ƒ há»i info video
        url = f"https://www.youtube.com/oembed?url=https://www.youtube.com/watch?v={video_id}&format=json"
        
        response = requests.get(url, timeout=5)
        if response.status_code == 200:
            data = response.json()
            return {
                "title": data.get("title"),
                "author_name": data.get("author_name"), # Tiá»‡n thá»ƒ láº¥y luÃ´n tÃªn kÃªnh chuáº©n
                "author_url": data.get("author_url")
            }
    except Exception as e:
        print(f"âš ï¸ Lá»—i gá»i oEmbed cho video {video_id}: {e}")
    
    return None

# === 2. HÃ€M TÃŒM TEXT Äá»† QUY (GIá»® Láº I) ===
def find_text_recursive(data, target_keys=['text', 'simpleText', 'label']):
    found_texts = []
    if isinstance(data, dict):
        for k, v in data.items():
            if k in target_keys and isinstance(v, str):
                if len(v) > 5 and not v.replace(':', '').isdigit(): 
                    found_texts.append(v)
            elif isinstance(v, (dict, list)):
                found_texts.extend(find_text_recursive(v, target_keys))
    elif isinstance(data, list):
        for item in data:
            found_texts.extend(find_text_recursive(item, target_keys))
    return found_texts

# === 3. HÃ€M TRÃCH XUáº¤T TIÃŠU Äá»€ (LOGIC Má»šI) ===
def extract_video_info(video):
    """
    Tráº£ vá» (title, channel_name_fallback)
    """
    video_id = video.get('videoId')
    title = None

    # CÃCH 1: TÃ¬m trong JSON cÃ³ sáºµn (Nhanh nháº¥t)
    try:
        if 'headline' in video: title = video['headline']['runs'][0]['text']
        elif 'title' in video:
            if 'runs' in video['title']: title = video['title']['runs'][0]['text']
            elif 'simpleText' in video['title']: title = video['title']['simpleText']
    except: pass

    # CÃCH 2: VÃ©t cáº¡n recursive
    if not title:
        candidates = find_text_recursive(video)
        if candidates: title = max(candidates, key=len)

    # CÃCH 3: Gá»ŒI Cá»¨U VIá»†N (Náº¿u CÃ¡ch 1 & 2 tháº¥t báº¡i)
    if not title or title == "Unknown Title":
        print(f"ğŸ”¦ Äang gá»i API oEmbed Ä‘á»ƒ láº¥y info cho: {video_id}...")
        fallback_data = fetch_video_info_fallback(video_id)
        if fallback_data and fallback_data.get("title"):
            return fallback_data["title"]

    return title if title else "Unknown Title"

# === 4. CÃC HÃ€M Há»– TRá»¢ KHÃC ===
def get_channel_details(channel_id):
    url = f"https://www.youtube.com/channel/{channel_id}"
    print(f"ğŸ”„ Äang cáº­p nháº­t info kÃªnh: {url}")
    try:
        headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)", "Accept-Language": "en-US"}
        response = requests.get(url, headers=headers, timeout=10)
        html = response.text
        
        channel_name = f"Channel {channel_id}"
        name_match = re.search(r'<meta property="og:title" content="(.*?)">', html)
        if name_match: channel_name = name_match.group(1)
        
        avatar_url = "https://via.placeholder.com/150"
        avatar_match = re.search(r'<meta property="og:image" content="(.*?)">', html)
        if avatar_match: avatar_url = avatar_match.group(1)
        
        return channel_name, avatar_url
    except: return f"Channel {channel_id}", "https://via.placeholder.com/150"

def get_channel_id_from_url(url):
    try:
        headers = {"User-Agent": "Mozilla/5.0"}
        response = requests.get(url, headers=headers, timeout=10)
        match = re.search(r'"browseId":"(UC[\w-]+)"', response.text)
        if match: return match.group(1)
        match = re.search(r'itemprop="identifier" content="(UC[\w-]+)"', response.text)
        if match: return match.group(1)
        return None
    except: return None

# === 5. WORKER CHÃNH ===
def sync_channel_data(channel_id, limit=100):
    """HÃ m cá»‘t lÃµi: QuÃ©t video tá»« ID kÃªnh vÃ  lÆ°u vÃ o DB"""
    print(f"ğŸš€ Worker: Báº¯t Ä‘áº§u quÃ©t video kÃªnh {channel_id}...")
    try:
        # Láº¥y sá»‘ video má»›i nháº¥t theo limit
        videos = scrapetube.get_channel(channel_id=channel_id, content_type="shorts", sleep=1, limit=limit)
        count = 0
        for video in videos:
            try:
                if 'videoId' not in video: continue
                video_id = video['videoId']
                
                title = extract_video_info(video)
                thumbnail_url = f"https://i.ytimg.com/vi/{video_id}/hqdefault.jpg"
                
                if title == "Unknown Title": continue

                add_video_to_db(channel_id, video_id, title, thumbnail_url)
                count += 1
            except Exception as e: 
                continue
    except Exception as e:
        print(f"âš ï¸ Worker: Lá»—i khi cÃ o video: {e}")

    print(f"âœ… Worker: QuÃ©t xong {count} video cho kÃªnh {channel_id}.")

    # Cáº­p nháº­t láº¡i Avatar/TÃªn kÃªnh luÃ´n cho má»›i
    new_name, new_avatar = get_channel_details(channel_id)
    add_channel_to_db(channel_id, new_name, new_avatar)
    
    return True

def sync_full_channel(channel_url):
    """DÃ¹ng cho lÃºc Add Channel (CÃ³ URL)"""
    real_channel_id = get_channel_id_from_url(channel_url)
    if not real_channel_id:
        print(f"âŒ Worker: KhÃ´ng láº¥y Ä‘Æ°á»£c ID tá»« {channel_url}")
        return
    
    # Gá»i hÃ m chung
    sync_channel_data(real_channel_id)
    return real_channel_id

def sync_channel_by_id(channel_id):
    """DÃ¹ng cho lÃºc Reload (Chá»‰ cÃ³ ID)"""
    sync_channel_data(channel_id)


