import scrapetube
import requests
import re
import json
import time
from database import add_video_to_db, add_channel_to_db

# === 1. H√ÄM C·ª®U VI·ªÜN (G·ªåI OEMBED) ===
def fetch_video_info_fallback(video_id):
    """
    Khi scrapetube kh√¥ng tr·∫£ v·ªÅ title, d√πng h√†m n√†y ƒë·ªÉ h·ªèi tr·ª±c ti·∫øp YouTube.
    API: oEmbed (C√¥ng khai, kh√¥ng c·∫ßn key, r·∫•t nhanh)
    """
    try:
        # URL chu·∫©n ƒë·ªÉ h·ªèi info video
        url = f"https://www.youtube.com/oembed?url=https://www.youtube.com/watch?v={video_id}&format=json"
        
        response = requests.get(url, timeout=5)
        if response.status_code == 200:
            data = response.json()
            return {
                "title": data.get("title"),
                "author_name": data.get("author_name"), # Ti·ªán th·ªÉ l·∫•y lu√¥n t√™n k√™nh chu·∫©n
                "author_url": data.get("author_url")
            }
    except Exception as e:
        print(f"‚ö†Ô∏è L·ªói g·ªçi oEmbed cho video {video_id}: {e}")
    
    return None

# === 2. H√ÄM T√åM TEXT ƒê·ªÜ QUY (GI·ªÆ L·∫†I) ===
def find_text_recursive(data, target_keys=['text', 'simpleText', 'label']):
    found_texts = []
    if isinstance(data, dict):
        for k, v in data.items():
            if k in target_keys and isinstance(v, str):
                if len(v) > 5 and not v.replace(':', '').isdigit(): 
                    found_texts.append(v)
            elif isinstance(v, (dict, list)):
                found_texts.extend(find_text_recursive(v, target_keys))
    elif isinstance(data, list):
        for item in data:
            found_texts.extend(find_text_recursive(item, target_keys))
    return found_texts

# === 3. H√ÄM TR√çCH XU·∫§T TI√äU ƒê·ªÄ (LOGIC M·ªöI) ===
def extract_video_info(video):
    """
    Tr·∫£ v·ªÅ (title, channel_name_fallback)
    """
    video_id = video.get('videoId')
    title = None

    # C√ÅCH 1: T√¨m trong JSON c√≥ s·∫µn (Nhanh nh·∫•t)
    try:
        if 'headline' in video: title = video['headline']['runs'][0]['text']
        elif 'title' in video:
            if 'runs' in video['title']: title = video['title']['runs'][0]['text']
            elif 'simpleText' in video['title']: title = video['title']['simpleText']
    except: pass

    # C√ÅCH 2: V√©t c·∫°n recursive
    if not title:
        candidates = find_text_recursive(video)
        if candidates: title = max(candidates, key=len)

    # C√ÅCH 3: G·ªåI C·ª®U VI·ªÜN (N·∫øu C√°ch 1 & 2 th·∫•t b·∫°i)
    if not title or title == "Unknown Title":
        print(f"üî¶ ƒêang g·ªçi API oEmbed ƒë·ªÉ l·∫•y info cho: {video_id}...")
        fallback_data = fetch_video_info_fallback(video_id)
        if fallback_data and fallback_data.get("title"):
            return fallback_data["title"]

    return title if title else "Unknown Title"

# === 4. C√ÅC H√ÄM H·ªñ TR·ª¢ KH√ÅC ===
def get_channel_details(channel_id):
    url = f"https://www.youtube.com/channel/{channel_id}"
    print(f"üîÑ ƒêang c·∫≠p nh·∫≠t info k√™nh: {url}")
    try:
        headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)", "Accept-Language": "en-US"}
        response = requests.get(url, headers=headers, timeout=10)
        html = response.text
        
        # 1. L·∫•y T√™n
        channel_name = f"Channel {channel_id}"
        name_match = re.search(r'<meta property="og:title" content="(.*?)">', html)
        if name_match: channel_name = name_match.group(1)
        
        # 2. L·∫•y Avatar
        avatar_url = "https://via.placeholder.com/150"
        avatar_match = re.search(r'<meta property="og:image" content="(.*?)">', html)
        if avatar_match: avatar_url = avatar_match.group(1)

        # 3. L·∫•y M√¥ t·∫£ (N√¢ng c·∫•p)
        description = ""
        
        # C√°ch 1: Th·ª≠ t√¨m trong JSON (Th∆∞·ªùng ch·ª©a full text nh·∫•t)
        json_match = re.search(r'"description":\{"simpleText":"(.*?)"\}', html)
        if json_match:
            # Gi·∫£i m√£ k√Ω t·ª± xu·ªëng d√≤ng c·ªßa JSON
            description = json_match.group(1).replace('\\n', '\n')
        
        # C√°ch 2: N·∫øu kh√¥ng c√≥ JSON, d√πng th·∫ª Meta (Th√™m re.DOTALL ƒë·ªÉ l·∫•y xu·ªëng d√≤ng)
        if not description:
            desc_match = re.search(r'<meta property="og:description" content="(.*?)">', html, re.DOTALL)
            if desc_match: description = desc_match.group(1)
        
        # Cleanup: X√≥a c√°c k√Ω t·ª± th·ª´a n·∫øu c√≥
        if description:
            description = description.replace('&quot;', '"').replace('&#39;', "'")

        return channel_name, avatar_url, description
    except Exception as e:
        print(f"‚ö†Ô∏è L·ªói l·∫•y info k√™nh {channel_id}: {e}")
        return f"Channel {channel_id}", "https://via.placeholder.com/150", ""

def get_channel_id_from_url(url):
    try:
        headers = {"User-Agent": "Mozilla/5.0"}
        response = requests.get(url, headers=headers, timeout=10)
        match = re.search(r'"browseId":"(UC[\w-]+)"', response.text)
        if match: return match.group(1)
        match = re.search(r'itemprop="identifier" content="(UC[\w-]+)"', response.text)
        if match: return match.group(1)
        return None
    except: return None

# === 5. WORKER CH√çNH ===
def sync_channel_data(channel_id, limit=100):
    """H√†m c·ªët l√µi: Qu√©t video t·ª´ ID k√™nh v√† l∆∞u v√†o DB"""
    print(f"üöÄ Worker: B·∫Øt ƒë·∫ßu qu√©t video k√™nh {channel_id}...")
    try:
        # L·∫•y s·ªë video m·ªõi nh·∫•t theo limit
        videos = scrapetube.get_channel(channel_id=channel_id, content_type="shorts", sleep=1, limit=limit)
        count = 0
        for video in videos:
            try:
                if 'videoId' not in video: continue
                video_id = video['videoId']
                
                title = extract_video_info(video)
                thumbnail_url = f"https://i.ytimg.com/vi/{video_id}/hqdefault.jpg"
                
                if title == "Unknown Title": continue

                add_video_to_db(channel_id, video_id, title, thumbnail_url)
                count += 1
            except Exception as e: 
                continue
    except Exception as e:
        print(f"‚ö†Ô∏è Worker: L·ªói khi c√†o video: {e}")

    print(f"‚úÖ Worker: Qu√©t xong {count} video cho k√™nh {channel_id}.")

    # C·∫≠p nh·∫≠t l·∫°i Avatar/T√™n/M√¥ t·∫£ 
    new_name, new_avatar, new_desc = get_channel_details(channel_id)
    # G·ªçi h√†m DB m·ªõi c√≥ th√™m tham s·ªë description
    add_channel_to_db(channel_id, new_name, new_avatar, new_desc)
    
    return True

def sync_full_channel(channel_url):
    """D√πng cho l√∫c Add Channel (C√≥ URL)"""
    real_channel_id = get_channel_id_from_url(channel_url)
    if not real_channel_id:
        print(f"‚ùå Worker: Kh√¥ng l·∫•y ƒë∆∞·ª£c ID t·ª´ {channel_url}")
        return
    
    # G·ªçi h√†m chung
    sync_channel_data(real_channel_id)
    return real_channel_id

def sync_channel_by_id(channel_id):
    """D√πng cho l√∫c Reload (Ch·ªâ c√≥ ID)"""
    sync_channel_data(channel_id)


